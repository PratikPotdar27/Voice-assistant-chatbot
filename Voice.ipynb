{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " * Serving Flask app \"__main__\" (lazy loading)\n",
      " * Environment: production\n",
      "   WARNING: This is a development server. Do not use it in a production deployment.\n",
      "   Use a production WSGI server instead.\n",
      " * Debug mode: off\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " * Running on http://127.0.0.1:5000/ (Press CTRL+C to quit)\n",
      "127.0.0.1 - - [01/Dec/2020 14:31:28] \"\u001b[37mGET / HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [01/Dec/2020 14:31:28] \"\u001b[33mGET /bg.jpg HTTP/1.1\u001b[0m\" 404 -\n",
      "127.0.0.1 - - [01/Dec/2020 14:31:51] \"\u001b[37mPOST /result HTTP/1.1\u001b[0m\" 200 -\n",
      "127.0.0.1 - - [01/Dec/2020 14:31:51] \"\u001b[33mGET /bg.jpg HTTP/1.1\u001b[0m\" 404 -\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ImmutableMultiDict([('Name', '')])\n"
     ]
    }
   ],
   "source": [
    "from flask import Flask, render_template, request\n",
    "app = Flask(__name__)\n",
    "\n",
    "@app.route('/')\n",
    "def index():\n",
    "   return render_template('voice.html')\n",
    "\n",
    "@app.route('/result',methods = ['POST', 'GET'])\n",
    "def result():\n",
    "   if request.method == 'POST':\n",
    "      result = request.form\n",
    "      print(result)  \n",
    "      return render_template(\"voice2.html\",result = result)\n",
    "\n",
    "if __name__=='__main__':\n",
    "    app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tkinter as tk\n",
    "import threading\n",
    "import pyaudio\n",
    "import wave\n",
    "\n",
    "class App():\n",
    "    chunk = 1024 \n",
    "    sample_format = pyaudio.paInt16 \n",
    "    channels = 2\n",
    "    fs = 44100  \n",
    "    \n",
    "    frames = []  \n",
    "    def __init__(self, master):\n",
    "        self.isrecording = False\n",
    "        self.button1 = tk.Button(main, text='rec',command=self.startrecording)\n",
    "        self.button2 = tk.Button(main, text='stop',command=self.stoprecording)\n",
    "      \n",
    "        self.button1.pack()\n",
    "        self.button2.pack()\n",
    "\n",
    "    def startrecording(self):\n",
    "        self.p = pyaudio.PyAudio()  \n",
    "        self.stream = self.p.open(format=self.sample_format,channels=self.channels,rate=self.fs,frames_per_buffer=self.chunk,input=True)\n",
    "        self.isrecording = True\n",
    "        \n",
    "        print('Recording')\n",
    "        t = threading.Thread(target=self.record)\n",
    "        t.start()\n",
    "\n",
    "    def stoprecording(self):\n",
    "        self.isrecording = False\n",
    "        print('recording complete')\n",
    "        self.filename=input('the filename?')\n",
    "        self.filename = self.filename+\".wav\"\n",
    "        wf = wave.open(self.filename, 'wb')\n",
    "        wf.setnchannels(self.channels)\n",
    "        wf.setsampwidth(self.p.get_sample_size(self.sample_format))\n",
    "        wf.setframerate(self.fs)\n",
    "        wf.writeframes(b''.join(self.frames))\n",
    "        wf.close()\n",
    "        main.destroy()\n",
    "    def record(self):\n",
    "       \n",
    "        while self.isrecording:\n",
    "            data = self.stream.read(self.chunk)\n",
    "            self.frames.append(data)\n",
    "\t\t\n",
    "\n",
    "main = tk.Tk()\n",
    "main.title('recorder')\n",
    "main.geometry('200x50')\n",
    "app = App(main)\n",
    "main.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import speech_recognition as sr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = \"p4.wav\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = sr.Recognizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hello how are you can I help you\n"
     ]
    }
   ],
   "source": [
    "# open the file\n",
    "with sr.AudioFile(filename) as source:\n",
    "    # listen for the data (load audio to memory)\n",
    "    audio_data = r.record(source)\n",
    "    # recognize (convert from speech to text)\n",
    "    text = r.recognize_google(audio_data)\n",
    "    print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello guys how are you I will never buy this product what you are thought on this please let me know'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "########"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def getSound(self):\n",
    "# Current chunk of audio data\n",
    "    data = self.stream.read(self.CHUNK)\n",
    "    self.frames.append(data)\n",
    "    wave = self.save(list(self.frames))\n",
    "\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pyqt5 in c:\\users\\dell\\anaconda2\\envs\\tensorflow\\lib\\site-packages (5.15.2)\n",
      "Requirement already satisfied: PyQt5-sip<13,>=12.8 in c:\\users\\dell\\anaconda2\\envs\\tensorflow\\lib\\site-packages (from pyqt5) (12.8.1)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install pyqt5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5 import QtWidgets, QtGui,QtCore\n",
    "from PyQt5.QtGui import QMovie\n",
    "import sys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.QtWidgets import *\n",
    "from PyQt5.QtCore import *\n",
    "from PyQt5.QtGui import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PyQt5.uic import loadUiType\n",
    "import pyttsx3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Futurastic GUI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tkinter import *\n",
    "import cv2\n",
    "import PIL.Image, PIL.ImageTk\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import speech_recognition as sr\n",
    "#import wikipedia\n",
    "import webbrowser\n",
    "import os\n",
    "import random\n",
    "import smtplib\n",
    "#import roman\n",
    "#from Class1 import Student\n",
    "#import pytesseract\n",
    "from PIL import Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "numbers = {'hundred':100, 'thousand':1000, 'lakh':100000}\n",
    "a = {'name':'your email'}\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "window = Tk()\n",
    "\n",
    "global var\n",
    "global var1\n",
    "\n",
    "var = StringVar()\n",
    "var1 = StringVar()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing\n"
     ]
    }
   ],
   "source": [
    "numbers = {'hundred':100, 'thousand':1000, 'lakh':100000}\n",
    "a = {'name':'pratik'}\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "window = Tk()\n",
    "\n",
    "global var\n",
    "global var1\n",
    "\n",
    "var = StringVar()\n",
    "var1 = StringVar()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "def wishme():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour >= 0 and hour <= 12:\n",
    "        var.set(\"Good Morning Pratik\") #Name - your Name\n",
    "        window.update()\n",
    "        speak(\"Good Morning Pratik!\")\n",
    "    elif hour >= 12 and hour <= 18:\n",
    "        var.set(\"Good Afternoon Pratik!\")\n",
    "        window.update()\n",
    "        speak(\"Good Afternoon Pratik!\")\n",
    "    else:\n",
    "        var.set(\"Good Evening Pratik\")\n",
    "        window.update()\n",
    "        speak(\"Good Evening Pratik!\")\n",
    "    speak(\"Myself PSP! How may I help you sir\") #BotName - Give a name to your assistant\n",
    "\n",
    "    \n",
    "def takeCommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        var.set(\"Listening...\")\n",
    "        window.update()\n",
    "        print(\"Listening...\")\n",
    "        r.pause_threshold = 1\n",
    "        r.energy_threshold = 400\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        var.set(\"Recognizing...\")\n",
    "        window.update()\n",
    "        print(\"Recognizing\")\n",
    "        query = r.recognize_google(audio, language='en-in')\n",
    "    except Exception as e:\n",
    "        return \"None\"\n",
    "    var1.set(query)\n",
    "    window.update()\n",
    "    return query\n",
    "\n",
    "\n",
    "def play():\n",
    "    btn2['state'] = 'disabled'\n",
    "    btn0['state'] = 'disabled'\n",
    "    btn1.configure(bg = 'orange')\n",
    "    wishme()\n",
    "    while True:\n",
    "        btn1.configure(bg = 'orange')\n",
    "        query = takeCommand().lower()\n",
    "        \n",
    "        voc_size=5000\n",
    "        import nltk\n",
    "        import re\n",
    "        from nltk.corpus import stopwords\n",
    "        from nltk.stem.porter import PorterStemmer\n",
    "        ps = PorterStemmer()\n",
    "        corpus = []\n",
    "        review = re.sub('[^a-zA-Z]', ' ', query)\n",
    "        review = review.lower()\n",
    "        review = review.split()\n",
    "        review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "        review = ' '.join(review)\n",
    "        corpus.append(review)\n",
    "        \n",
    "        from tensorflow.keras.layers import Embedding\n",
    "        from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "        from tensorflow.keras.models import Sequential\n",
    "        from tensorflow.keras.preprocessing.text import one_hot\n",
    "        from tensorflow.keras.layers import LSTM\n",
    "        from tensorflow.keras.layers import Dense\n",
    "    \n",
    "        onehot_repr=[one_hot(words,voc_size)for words in corpus]\n",
    "    \n",
    "        sent_length=20\n",
    "        embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "        import numpy as np\n",
    "        X_final=np.array(embedded_docs)\n",
    "        from tensorflow.keras.models import save_model, load_model\n",
    "        filepath= './saved_model'\n",
    "        model=load_model(filepath, compile = True)\n",
    "        predctn= model.predict_classes(X_final)        \n",
    "        \n",
    "        gg=np.reshape(predctn,1)\n",
    "        gg1=pd.Series(gg)\n",
    "        g1=gg1.get(key=0)\n",
    "        \n",
    "        \n",
    "        if g1==0:\n",
    "            fg=os.system('start hello3.mp3')\n",
    "        else:\n",
    "            fg1=os.system('start hello4.mp3')\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def update(ind):\n",
    "    frame = frames[(ind)%100]\n",
    "    ind += 1\n",
    "    label.configure(image=frame)\n",
    "    window.after(100, update, ind)\n",
    "\n",
    "label2 = Label(window, textvariable = var1, bg = '#FAB60C')\n",
    "label2.config(font=(\"Courier\", 20))\n",
    "var1.set('User Said:')\n",
    "label2.pack()\n",
    "\n",
    "label1 = Label(window, textvariable = var, bg = '#ADD8E6')\n",
    "label1.config(font=(\"Courier\", 20))\n",
    "var.set('Welcome')\n",
    "label1.pack()\n",
    "\n",
    "frames = [PhotoImage(file='Assistant.gif',format = 'gif -index %i' %(i)) for i in range(100)]\n",
    "window.title('JARVIS')\n",
    "\n",
    "label = Label(window, width = 500, height = 500)\n",
    "label.pack()\n",
    "window.after(0, update, 0)\n",
    "\n",
    "btn0 = Button(text = 'WISH ME',width = 20, command = wishme, bg = '#5C85FB')\n",
    "btn0.config(font=(\"Courier\", 12))\n",
    "btn0.pack()\n",
    "btn1 = Button(text = 'PLAY',width = 20,command = play, bg = '#5C85FB')\n",
    "btn1.config(font=(\"Courier\", 12))\n",
    "btn1.pack()\n",
    "btn2 = Button(text = 'EXIT',width = 20, command = window.destroy, bg = '#5C85FB')\n",
    "btn2.config(font=(\"Courier\", 12))\n",
    "btn2.pack()\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adding some more features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\ops\\resource_variable_ops.py:435: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From C:\\Users\\DELL\\Anaconda2\\envs\\tensorflow\\lib\\site-packages\\tensorflow\\python\\keras\\layers\\core.py:143: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n",
      "0    1\n",
      "dtype: int32\n",
      "Listening...\n",
      "Recognizing\n",
      "0    1\n",
      "dtype: int32\n",
      "Listening...\n",
      "Recognizing\n",
      "Listening...\n",
      "Recognizing\n",
      "0    1\n",
      "dtype: int32\n",
      "Listening...\n",
      "Recognizing\n",
      "0    1\n",
      "dtype: int32\n",
      "Listening...\n",
      "Recognizing\n"
     ]
    }
   ],
   "source": [
    "numbers = {'hundred':100, 'thousand':1000, 'lakh':100000}\n",
    "a = {'name':'pratik'}\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "window = Tk()\n",
    "\n",
    "global var\n",
    "global var1\n",
    "\n",
    "var = StringVar()\n",
    "var1 = StringVar()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "def wishme():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour >= 0 and hour <= 12:\n",
    "        var.set(\"Good Morning Customer\") #Name - your Name\n",
    "        window.update()\n",
    "        speak(\"Good Morning Customer!\")\n",
    "    elif hour >= 12 and hour <= 18:\n",
    "        var.set(\"Good Afternoon Customer!\")\n",
    "        window.update()\n",
    "        speak(\"Good Afternoon Customer!\")\n",
    "    else:\n",
    "        var.set(\"Good Evening Customer\")\n",
    "        window.update()\n",
    "        speak(\"Good Evening Customer!\")\n",
    "    speak(\"Myself Customer Service Robo! How may I help you dear\") #BotName - Give a name to your assistant\n",
    "\n",
    "    \n",
    "def takeCommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        var.set(\"Listening...\")\n",
    "        window.update()\n",
    "        print(\"Listening...\")\n",
    "        r.pause_threshold = 1\n",
    "        r.energy_threshold = 400\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        var.set(\"Recognizing...\")\n",
    "        window.update()\n",
    "        print(\"Recognizing\")\n",
    "        query = r.recognize_google(audio, language='en')\n",
    "    except Exception as e:\n",
    "        return \"None\"\n",
    "    var1.set(query)\n",
    "    window.update()\n",
    "    return query\n",
    "\n",
    "\n",
    "def query():\n",
    "    btn2['state'] = 'disabled'\n",
    "    btn0['state'] = 'disabled'\n",
    "    btn1.configure(bg = 'orange')\n",
    "    wishme()\n",
    "    while True:\n",
    "        btn1.configure(bg = 'orange')\n",
    "        query = takeCommand().lower()\n",
    "\n",
    "\n",
    "        if 'exit' in query:\n",
    "            var.set(\"Bye Dear Customer\")\n",
    "            btn1.configure(bg = '#5C85FB')\n",
    "            btn2['state'] = 'normal'\n",
    "            btn0['state'] = 'normal'\n",
    "            window.update()\n",
    "            speak(\"Bye Dear Customer\")\n",
    "            break \n",
    "            \n",
    "        else:\n",
    "            voc_size=5000\n",
    "            import nltk\n",
    "            import re\n",
    "            from nltk.corpus import stopwords\n",
    "            from nltk.stem.porter import PorterStemmer\n",
    "            ps = PorterStemmer()\n",
    "            corpus = []\n",
    "            review = re.sub('[^a-zA-Z]', ' ', query)\n",
    "            review = review.lower()\n",
    "            review = review.split()\n",
    "            review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "            review = ' '.join(review)\n",
    "            corpus.append(review)\n",
    "        \n",
    "            from tensorflow.keras.layers import Embedding\n",
    "            from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "            from tensorflow.keras.models import Sequential\n",
    "            from tensorflow.keras.preprocessing.text import one_hot\n",
    "            from tensorflow.keras.layers import LSTM\n",
    "            from tensorflow.keras.layers import Dense\n",
    "    \n",
    "            onehot_repr=[one_hot(words,voc_size)for words in corpus]\n",
    "    \n",
    "            sent_length=20\n",
    "            embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "            import numpy as np\n",
    "            X_final=np.array(embedded_docs)\n",
    "            from tensorflow.keras.models import save_model, load_model\n",
    "            filepath= './saved_model'\n",
    "            model=load_model(filepath, compile = True)\n",
    "            predctn= model.predict_classes(X_final)        \n",
    "            \n",
    "            #gg1.drop(0)\n",
    "            #g1.drop(0)\n",
    "            gg=np.reshape(predctn,1)\n",
    "            gg1=pd.Series(gg)\n",
    "            g1=gg1.get(key=0)\n",
    "        \n",
    "            print(gg1)        \n",
    "            if g1==0:\n",
    "                fg=os.system('start hello3.mp3')\n",
    "            else:\n",
    "                fg1=os.system('start hello4.mp3')\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "\n",
    "def update(ind):\n",
    "    frame = frames[(ind)%100]\n",
    "    ind += 1\n",
    "    label.configure(image=frame)\n",
    "    window.after(100, update, ind)\n",
    "\n",
    "label2 = Label(window, textvariable = var1, bg = '#FAB60C')\n",
    "label2.config(font=(\"Courier\", 20))\n",
    "var1.set('User Said:')\n",
    "label2.pack()\n",
    "\n",
    "label1 = Label(window, textvariable = var, bg = '#ADD8E6')\n",
    "label1.config(font=(\"Courier\", 20))\n",
    "var.set('Welcome')\n",
    "label1.pack()\n",
    "\n",
    "frames = [PhotoImage(file='Assistant.gif',format = 'gif -index %i' %(i)) for i in range(100)]\n",
    "window.title('JARVIS')\n",
    "\n",
    "label = Label(window, width = 500, height = 500)\n",
    "label.pack()\n",
    "window.after(0, update, 0)\n",
    "\n",
    "btn0 = Button(text = 'WISH ME',width = 20, command = wishme, bg = '#5C85FB')\n",
    "btn0.config(font=(\"Courier\", 12))\n",
    "btn0.pack()\n",
    "btn1 = Button(text = 'query',width = 20,command = query, bg = '#5C85FB')\n",
    "btn1.config(font=(\"Courier\", 12))\n",
    "btn1.pack()\n",
    "btn2 = Button(text = 'EXIT',width = 20, command = window.destroy, bg = '#5C85FB')\n",
    "btn2.config(font=(\"Courier\", 12))\n",
    "btn2.pack()\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'g1' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-384c83509d00>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mg1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m: name 'g1' is not defined"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####Trying something new with textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: textblob in c:\\users\\dell\\anaconda2\\envs\\tensorflow\\lib\\site-packages (0.15.3)\n",
      "Requirement already satisfied: nltk>=3.1 in c:\\users\\dell\\anaconda2\\envs\\tensorflow\\lib\\site-packages (from textblob) (3.4.5)\n",
      "Requirement already satisfied: six in c:\\users\\dell\\anaconda2\\envs\\tensorflow\\lib\\site-packages (from nltk>=3.1->textblob) (1.12.0)\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "pip install textblob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "text1='worst product never suggest anyone to bye this'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "blob=TextBlob(text1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('worst', 'JJS'),\n",
       " ('product', 'NN'),\n",
       " ('never', 'RB'),\n",
       " ('suggest', 'VBP'),\n",
       " ('anyone', 'NN'),\n",
       " ('to', 'TO'),\n",
       " ('bye', 'VB'),\n",
       " ('this', 'DT')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "blob.tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen= blob.sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Sentence(\"worst product never suggest anyone to bye this\")]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sen"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "    \n",
    "speak(\"You are offering extreamly worst services. You should say sorry for this. I hate that kind of service you are making me idiot\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa=['a','b','c','d']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "aa1=pd.Series(aa)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "b1=aa1.drop(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    b\n",
       "2    c\n",
       "3    d\n",
       "dtype: object"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#############Delete this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Transcription: hello guys how are you I will never buy this product what you are thought on this please let me know\n"
     ]
    }
   ],
   "source": [
    "import speech_recognition as sr\n",
    "from os import path\n",
    "from pydub import AudioSegment\n",
    "\n",
    "# convert mp3 file to wav                                                       \n",
    "sound = AudioSegment.from_wav(\"p1.wav\")\n",
    "sound.export(\"transcript.wav\", format=\"wav\")\n",
    "\n",
    "\n",
    "# transcribe audio file                                                         \n",
    "AUDIO_FILE ='transcript.wav'\n",
    "\n",
    "# use the audio file as the audio source                                        \n",
    "r = sr.Recognizer()\n",
    "with sr.AudioFile(AUDIO_FILE) as source:\n",
    "        audio = r.record(source)  # read the entire audio file                  \n",
    "\n",
    "        print(\"Transcription: \" + r.recognize_google(audio))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import speech_recognition as sr \n",
    "  \n",
    "import os \n",
    "  \n",
    "from pydub import AudioSegment \n",
    "from pydub.silence import split_on_silence \n",
    "  \n",
    "# a function that splits the audio file into chunks \n",
    "# and applies speech recognition \n",
    "path = \"aud_file.wav\"\n",
    "  \n",
    "    # open the audio file stored in \n",
    "    # the local system as a wav file. \n",
    "song = AudioSegment.from_wav(path) \n",
    "  \n",
    "    # open a file where we will concatenate   \n",
    "    # and store the recognized text \n",
    "fh = open(\"recognized.txt\", \"w+\") \n",
    "          \n",
    "    # split track where silence is 0.5 seconds  \n",
    "    # or more and get chunks \n",
    "chunks = split_on_silence(song \n",
    "        # must be silent for at least 0.5 seconds \n",
    "        # or 500 ms. adjust this value based on user \n",
    "        # requirement. if the speaker stays silent for  \n",
    "        # longer, increase this value. else, decrease it. \n",
    "        #min_silence_len = 5, \n",
    "  \n",
    "        # consider it silent if quieter than -16 dBFS \n",
    "        # adjust this per requirement \n",
    "        #silence_thresh = -1\n",
    ") \n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydub import AudioSegment\n",
    "from pydub.silence import split_on_silence\n",
    "\n",
    "sound = AudioSegment.from_file(\"aud_file.wav\", format=\"wav\")\n",
    "chunks = split_on_silence(\n",
    "    sound,\n",
    "\n",
    "    # split on silences longer than 1000ms (1 sec)\n",
    "    min_silence_len=1000,\n",
    "\n",
    "    # anything under -16 dBFS is considered silence\n",
    "    silence_thresh=-16, \n",
    "\n",
    "    # keep 200 ms of leading/trailing silence\n",
    "    keep_silence=200\n",
    ")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "271952"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(sound)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-37.72080671713998"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sound.dBFS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "chunks=split_on_silence(sound, silence_thresh=-37)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<pydub.audio_segment.AudioSegment at 0x223f74d36d8>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3908>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3978>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d38d0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d36a0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d35f8>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3780>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3518>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3588>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d37f0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d34e0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d35c0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3668>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3630>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3f60>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3fd0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3cf8>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3e48>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3e80>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3e10>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3a58>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3ef0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d3198>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f74d33c8>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223d9960e48>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea15f8>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea1278>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea1320>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea1048>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea1358>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea1400>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea1390>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea12b0>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea1128>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea10b8>,\n",
       " <pydub.audio_segment.AudioSegment at 0x223f4ea1160>]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chunks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Listening...\n",
      "Recognizing\n",
      "0    1\n",
      "dtype: int32\n",
      "Listening...\n",
      "Recognizing\n"
     ]
    }
   ],
   "source": [
    "from tkinter import *\n",
    "import cv2\n",
    "import PIL.Image, PIL.ImageTk\n",
    "import pyttsx3\n",
    "import datetime\n",
    "import speech_recognition as sr\n",
    "#import wikipedia\n",
    "#import webbrowser\n",
    "import os\n",
    "import random\n",
    "import smtplib\n",
    "#import roman\n",
    "#from Class1 import Student\n",
    "#import pytesseract\n",
    "from PIL import Image\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "numbers = {'hundred':100, 'thousand':1000, 'lakh':100000}\n",
    "a = {'name':'pratik'}\n",
    "engine = pyttsx3.init('sapi5')\n",
    "voices = engine.getProperty('voices')\n",
    "engine.setProperty('voice', voices[0].id)\n",
    "\n",
    "window = Tk()\n",
    "\n",
    "global var\n",
    "global var1\n",
    "\n",
    "var = StringVar()\n",
    "var1 = StringVar()\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def speak(audio):\n",
    "    engine.say(audio)\n",
    "    engine.runAndWait()\n",
    "    \n",
    "def wishme():\n",
    "    hour = int(datetime.datetime.now().hour)\n",
    "    if hour >= 0 and hour <= 12:\n",
    "        var.set(\"Good Morning Customer\") #Name - your Name\n",
    "        window.update()\n",
    "        speak(\"Good Morning Customer!\")\n",
    "    elif hour >= 12 and hour <= 18:\n",
    "        var.set(\"Good Afternoon Customer!\")\n",
    "        window.update()\n",
    "        speak(\"Good Afternoon Customer!\")\n",
    "    else:\n",
    "        var.set(\"Good Evening Customer\")\n",
    "        window.update()\n",
    "        speak(\"Good Evening Customer!\")\n",
    "    speak(\"Myself Customer Service Robo! How may I help you dear\") #BotName - Give a name to your assistant\n",
    "\n",
    "    \n",
    "def takeCommand():\n",
    "    r = sr.Recognizer()\n",
    "    with sr.Microphone() as source:\n",
    "        var.set(\"Listening...\")\n",
    "        window.update()\n",
    "        print(\"Listening...\")\n",
    "        r.pause_threshold = 1\n",
    "        r.energy_threshold = 400\n",
    "        audio = r.listen(source)\n",
    "    try:\n",
    "        var.set(\"Recognizing...\")\n",
    "        window.update()\n",
    "        print(\"Recognizing\")\n",
    "        query = r.recognize_google(audio, language='en')\n",
    "    except Exception as e:\n",
    "        return \"None\"\n",
    "    var1.set(query)\n",
    "    window.update()\n",
    "    return query\n",
    "\n",
    "\n",
    "def query():\n",
    "    btn2['state'] = 'disabled'\n",
    "    btn0['state'] = 'disabled'\n",
    "    btn1.configure(bg = 'orange')\n",
    "    wishme()\n",
    "    while True:\n",
    "        btn1.configure(bg = 'orange')\n",
    "        query = takeCommand().lower()\n",
    "\n",
    "\n",
    "        if 'exit' in query:\n",
    "            var.set(\"Bye Dear Customer\")\n",
    "            btn1.configure(bg = '#5C85FB')\n",
    "            btn2['state'] = 'normal'\n",
    "            btn0['state'] = 'normal'\n",
    "            window.update()\n",
    "            speak(\"Bye Dear Customer\")\n",
    "            break \n",
    "  ######Here I am using LSTM for detecting sentiment          \n",
    "        else:\n",
    "            voc_size=5000\n",
    "            import nltk\n",
    "            import re\n",
    "            from nltk.corpus import stopwords\n",
    "            from nltk.stem.porter import PorterStemmer\n",
    "            ps = PorterStemmer()\n",
    "            corpus = []\n",
    "            review = re.sub('[^a-zA-Z]', ' ', query)\n",
    "            review = review.lower()\n",
    "            review = review.split()\n",
    "            review = [ps.stem(word) for word in review if not word in stopwords.words('english')]\n",
    "            review = ' '.join(review)\n",
    "            corpus.append(review)\n",
    "        \n",
    "            from tensorflow.keras.layers import Embedding\n",
    "            from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "            from tensorflow.keras.models import Sequential\n",
    "            from tensorflow.keras.preprocessing.text import one_hot\n",
    "            from tensorflow.keras.layers import LSTM\n",
    "            from tensorflow.keras.layers import Dense\n",
    "    \n",
    "            onehot_repr=[one_hot(words,voc_size)for words in corpus]\n",
    "    \n",
    "            sent_length=20\n",
    "            embedded_docs=pad_sequences(onehot_repr,padding='pre',maxlen=sent_length)\n",
    "            import numpy as np\n",
    "            X_final=np.array(embedded_docs)\n",
    "            from tensorflow.keras.models import save_model, load_model\n",
    "            filepath= './saved_model'\n",
    "            model=load_model(filepath, compile = True)\n",
    "            predctn= model.predict_classes(X_final)        \n",
    "            \n",
    "            #gg1.drop(0)\n",
    "            #g1.drop(0)\n",
    "            gg=np.reshape(predctn,1)\n",
    "            gg1=pd.Series(gg)\n",
    "            g1=gg1.get(key=0)\n",
    "        \n",
    "            print(gg1)        \n",
    "            if g1==0:\n",
    "                speak(\"Thank you for reaching out. We are sorry for your inconvenience. We have successfully reported your query\")\n",
    "            else:\n",
    "                speak(\"Thank you for your kind word. We are always ready for your service\")\n",
    "        \n",
    "            \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "#####Creating GUI        \n",
    "        \n",
    "\n",
    "def update(ind):\n",
    "    frame = frames[(ind)%100]\n",
    "    ind += 1\n",
    "    label.configure(image=frame)\n",
    "    window.after(100, update, ind)\n",
    "\n",
    "label2 = Label(window, textvariable = var1, bg = '#FAB60C')\n",
    "label2.config(font=(\"Courier\", 20))\n",
    "var1.set('User Said:')\n",
    "label2.pack()\n",
    "\n",
    "label1 = Label(window, textvariable = var, bg = '#ADD8E6')\n",
    "label1.config(font=(\"Courier\", 20))\n",
    "var.set('Welcome')\n",
    "label1.pack()\n",
    "\n",
    "frames = [PhotoImage(file='Assistant.gif',format = 'gif -index %i' %(i)) for i in range(100)]\n",
    "window.title('Customer Care Robo')\n",
    "\n",
    "label = Label(window, width = 500, height = 500)\n",
    "label.pack()\n",
    "window.after(0, update, 0)\n",
    "\n",
    "btn0 = Button(text = 'WISH ME',width = 20, command = wishme, bg = '#5C85FB')\n",
    "btn0.config(font=(\"Courier\", 12))\n",
    "btn0.pack()\n",
    "btn1 = Button(text = 'query',width = 20,command = query, bg = '#5C85FB')\n",
    "btn1.config(font=(\"Courier\", 12))\n",
    "btn1.pack()\n",
    "btn2 = Button(text = 'EXIT',width = 20, command = window.destroy, bg = '#5C85FB')\n",
    "btn2.config(font=(\"Courier\", 12))\n",
    "btn2.pack()\n",
    "\n",
    "\n",
    "window.mainloop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
